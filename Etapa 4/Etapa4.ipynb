{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Etapa 4",
   "id": "ff25401100eeef14"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dependências",
   "id": "5d10061b7da58c28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T00:35:32.983103Z",
     "start_time": "2025-11-27T00:35:32.980418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score, precision_recall_curve"
   ],
   "id": "f6a7d26c8ded3525",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparação dos Dados",
   "id": "7ce0817cb8ad4eae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T00:35:33.044208Z",
     "start_time": "2025-11-27T00:35:33.027839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Carregamento dos dados processados\n",
    "df = pd.read_parquet(\"NYPD-Tidy.parquet\")\n",
    "df.shape\n",
    "\n",
    "# Remove as colunas latitude e longitude\n",
    "X = df.drop(columns=[\"STATISTICAL_MURDER_FLAG\", \"Latitude\", \"Longitude\"], errors=\"ignore\")\n",
    "y = df[\"STATISTICAL_MURDER_FLAG\"]\n",
    "\n",
    "\n",
    "# Identifica os tipos de colunas\n",
    "categoricas = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "numericas = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "# Pipeline com imputação + transformação\n",
    "preprocessador = ColumnTransformer([\n",
    "    (\"num\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]), numericas),\n",
    "\n",
    "    (\"cat\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]), categoricas)\n",
    "])\n"
   ],
   "id": "f6db4a26dc840f09",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T00:35:33.083263Z",
     "start_time": "2025-11-27T00:35:33.073292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Divisão em treino e teste\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n"
   ],
   "id": "832958111020e750",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Modelos Testados",
   "id": "3656ae3903baf580"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Regressão Logística, Random Forest e XGBoost (Sem Ajustes)",
   "id": "b5401a7a455349c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T00:36:35.651738Z",
     "start_time": "2025-11-27T00:35:33.119431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Função para treinar, avaliar e imprimir resultados de um modelo\n",
    "def avaliar(modelo, nome):\n",
    "    # Cria um pipeline com duas etapas:\n",
    "    # 1. 'prep': o pré-processador (ex: OneHotEncoder, StandardScaler etc.)\n",
    "    # 2. 'model': o modelo de aprendizado de máquina passado como argumento\n",
    "    pipe = Pipeline(steps=[(\"prep\", preprocessador), (\"model\", modelo)])\n",
    "\n",
    "    # Treina o pipeline nos dados de treino\n",
    "    pipe.fit(X_treino, y_treino)\n",
    "\n",
    "    # Faz previsões nos dados de teste (rótulos binários)\n",
    "    pred = pipe.predict(X_teste)\n",
    "\n",
    "    # Calcula as probabilidades de classe positiva (para métricas baseadas em score)\n",
    "    prob = pipe.predict_proba(X_teste)[:, 1]\n",
    "\n",
    "    # Exibe nome do modelo e relatório de classificação (precision, recall, f1-score, support)\n",
    "    print(f\"\\n===== {nome} =====\")\n",
    "    print(classification_report(y_teste, pred))\n",
    "\n",
    "    # Exibe a métrica ROC-AUC com base nas probabilidades preditas\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_teste, prob))\n",
    "\n",
    "    # Retorna o pipeline treinado, caso se deseje reutilizar\n",
    "    return pipe\n",
    "\n",
    "# Avaliação com Regressão Logística (com máximo de 1000 iterações para garantir convergência)\n",
    "modelo_lr = avaliar(LogisticRegression(max_iter=1000), \"Regressão Logística\")\n",
    "\n",
    "# Avaliação com Random Forest (usando semente para reprodutibilidade)\n",
    "modelo_rf = avaliar(RandomForestClassifier(random_state=42), \"Random Forest\")\n",
    "\n",
    "# Avaliação com XGBoost (definindo a métrica de avaliação como logloss)\n",
    "modelo_xgb = avaliar(XGBClassifier(eval_metric='logloss'), \"XGBoost\")\n"
   ],
   "id": "c5fea77ac7a16f64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Regressão Logística =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89      4595\n",
      "           1       0.45      0.09      0.15      1104\n",
      "\n",
      "    accuracy                           0.80      5699\n",
      "   macro avg       0.64      0.53      0.52      5699\n",
      "weighted avg       0.75      0.80      0.75      5699\n",
      "\n",
      "ROC-AUC: 0.6803150281496901\n",
      "\n",
      "===== Random Forest =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.87      4595\n",
      "           1       0.15      0.04      0.07      1104\n",
      "\n",
      "    accuracy                           0.77      5699\n",
      "   macro avg       0.48      0.49      0.47      5699\n",
      "weighted avg       0.68      0.77      0.71      5699\n",
      "\n",
      "ROC-AUC: 0.6368048327577234\n",
      "\n",
      "===== XGBoost =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89      4595\n",
      "           1       0.48      0.06      0.10      1104\n",
      "\n",
      "    accuracy                           0.81      5699\n",
      "   macro avg       0.64      0.52      0.50      5699\n",
      "weighted avg       0.75      0.81      0.74      5699\n",
      "\n",
      "ROC-AUC: 0.6751665720458596\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Após Ajustes",
   "id": "fc51e6026a64f1b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Regressão Logística Final",
   "id": "6c285c080902095b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T00:36:49.055623Z",
     "start_time": "2025-11-27T00:36:35.831497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pipeline com UNDERSAMPLING\n",
    "pipe_lr = Pipeline(steps=[\n",
    "    (\"prep\", preprocessador),                                  # Etapa de pré-processamento (ex: encoding, scaling etc.)\n",
    "    (\"undersample\", RandomUnderSampler(random_state=42)),      # Redução da classe majoritária (undersampling)\n",
    "    (\"model\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))  # Modelo: regressão logística\n",
    "    # 'class_weight=\"balanced\"' reforça o tratamento de desbalanceamento mesmo após o undersampling\n",
    "])\n",
    "\n",
    "# Grade de hiperparâmetros para busca por validação cruzada\n",
    "param_grid_lr = {\n",
    "    \"model__C\": [0.01, 0.1, 1, 10],          # C: força da regularização (quanto menor, mais regularização)\n",
    "    \"model__penalty\": [\"l2\"],               # Penalidade: L2 (ridge)\n",
    "    \"model__solver\": [\"lbfgs\"],             # Solver usado para otimização (funciona bem com L2)\n",
    "}\n",
    "\n",
    "# Busca dos melhores hiperparâmetros com validação cruzada (3 folds)\n",
    "grid_lr = GridSearchCV(\n",
    "    pipe_lr, param_grid_lr,\n",
    "    scoring=\"f1\",              # Otimiza F1-score (balanceia precisão e recall)\n",
    "    cv=3,                      # 3 folds de validação cruzada\n",
    "    verbose=1,                 # Mostra o andamento do processo\n",
    "    n_jobs=-1                  # Usa todos os núcleos da CPU para acelerar\n",
    ")\n",
    "grid_lr.fit(X_treino, y_treino)  # Treina a busca com undersampling\n",
    "\n",
    "# Resultados do tuning\n",
    "print(\"Melhores parâmetros (LogReg + UnderSampling):\", grid_lr.best_params_)\n",
    "print(\"Melhor F1-score (CV):\", grid_lr.best_score_)\n",
    "\n",
    "# Avaliação no conjunto de teste\n",
    "best_lr = grid_lr.best_estimator_                 # Melhor pipeline encontrado\n",
    "pred = best_lr.predict(X_teste)                   # Previsões de classe\n",
    "prob = best_lr.predict_proba(X_teste)[:, 1]       # Probabilidades da classe positiva\n",
    "\n",
    "# Impressão dos resultados finais no teste\n",
    "print(\"\\n== Regressão Logística + UnderSampling ==\")\n",
    "print(classification_report(y_teste, pred))       # Relatório com precisão, recall, F1 e suporte\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_teste, prob))   # Curva ROC-AUC (discriminação global)\n"
   ],
   "id": "b56ff25ea357d754",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Melhores parâmetros (LogReg + UnderSampling): {'model__C': 1, 'model__penalty': 'l2', 'model__solver': 'lbfgs'}\n",
      "Melhor F1-score (CV): 0.3816119637143389\n",
      "\n",
      "== Regressão Logística + UnderSampling ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.62      0.72      4595\n",
      "           1       0.28      0.62      0.39      1104\n",
      "\n",
      "    accuracy                           0.62      5699\n",
      "   macro avg       0.58      0.62      0.55      5699\n",
      "weighted avg       0.76      0.62      0.66      5699\n",
      "\n",
      "ROC-AUC: 0.6672745067890429\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Random Forest Final",
   "id": "76aa8dd5f629abf6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T00:37:14.624689Z",
     "start_time": "2025-11-27T00:36:49.239192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pipeline com Random Forest otimizado para eficiência\n",
    "pipe_rf_fast = Pipeline([\n",
    "    (\"prep\", preprocessador),  # Etapa de pré-processamento (ex: encoding, scaling etc.)\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=200,            # Número de árvores (pode ser 100 para ganhar velocidade)\n",
    "        max_depth=12,                # Profundidade máxima das árvores (controla overfitting)\n",
    "        min_samples_leaf=2,          # Tamanho mínimo da folha (evita árvores muito ramificadas)\n",
    "        min_samples_split=5,         # Mínimo de amostras para dividir um nó interno\n",
    "        max_features=\"sqrt\",         # Nº de features considerado por split (raiz quadrada)\n",
    "        bootstrap=True,              # Usa amostragem com reposição (bagging)\n",
    "        max_samples=0.6,             # Subamostra de dados por árvore (60% das amostras)\n",
    "        class_weight=\"balanced_subsample\",  # Corrige desbalanceamento em cada árvore\n",
    "        n_jobs=-1,                   # Usa todos os núcleos disponíveis\n",
    "        random_state=42             # Reprodutibilidade\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Espaço de busca para tuning dos hiperparâmetros (mais leve)\n",
    "param_grid_fast = {\n",
    "    \"model__n_estimators\": [100, 200],             # Nº de árvores\n",
    "    \"model__max_depth\": [8, 12],                   # Profundidade das árvores\n",
    "    \"model__max_samples\": [0.5, 0.6, 0.7],         # Proporção de amostras por árvore\n",
    "    \"model__min_samples_leaf\": [2, 4],             # Tamanho mínimo da folha\n",
    "    \"model__max_features\": [\"sqrt\", 0.3],          # Nº de features por split\n",
    "}\n",
    "\n",
    "# Validação cruzada estratificada (mantém proporções das classes)\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Busca dos melhores hiperparâmetros com PR-AUC como métrica (ideal p/ desbalanceamento)\n",
    "grid_fast = GridSearchCV(\n",
    "    pipe_rf_fast,\n",
    "    param_grid_fast,\n",
    "    scoring=\"average_precision\",   # Otimiza área sob a curva de precisão-recall\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Treina o modelo com busca de hiperparâmetros\n",
    "grid_fast.fit(X_treino, y_treino)\n",
    "\n",
    "# Melhor pipeline encontrado\n",
    "best = grid_fast.best_estimator_\n",
    "\n",
    "# Avaliação no conjunto de teste\n",
    "prob = best.predict_proba(X_teste)[:,1]       # Probabilidade da classe positiva\n",
    "pred = (prob >= 0.5).astype(int)              # Threshold padrão (0.5)\n",
    "\n",
    "# Impressão dos resultados\n",
    "print(\"Melhores params (RF-Lite):\", grid_fast.best_params_)  # Hiperparâmetros otimizados\n",
    "print(\"PR-AUC:\", average_precision_score(y_teste, prob))     # Área sob a curva precisão-recall\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_teste, prob))              # Área sob a curva ROC\n",
    "print(classification_report(y_teste, pred))                  # Métricas: precisão, recall e F1\n"
   ],
   "id": "8bd7d9aee5ff5846",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores params (RF-Lite): {'model__max_depth': 8, 'model__max_features': 0.3, 'model__max_samples': 0.7, 'model__min_samples_leaf': 4, 'model__n_estimators': 200}\n",
      "PR-AUC: 0.3034867155166983\n",
      "ROC-AUC: 0.6558064649666462\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.61      0.72      4595\n",
      "           1       0.28      0.63      0.38      1104\n",
      "\n",
      "    accuracy                           0.61      5699\n",
      "   macro avg       0.57      0.62      0.55      5699\n",
      "weighted avg       0.76      0.61      0.65      5699\n",
      "\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### XGBoost Final",
   "id": "d7220e80f0b324df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T00:37:23.741123Z",
     "start_time": "2025-11-27T00:37:14.845200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cálculo do peso da classe positiva (para lidar com desbalanceamento)\n",
    "neg = int((y_treino == 0).sum())  # Total da classe negativa\n",
    "pos = int((y_treino == 1).sum())  # Total da classe positiva\n",
    "spw = max(1.0, neg / max(1, pos))  # Peso para XGBoost (evita divisão por zero)\n",
    "\n",
    "# Pipeline com XGBoost e pré-processamento\n",
    "pipe_xgb = Pipeline(steps=[\n",
    "    (\"prep\", preprocessador),  # Aplicação do ColumnTransformer\n",
    "    (\"model\", XGBClassifier(\n",
    "        objective=\"binary:logistic\",  # Tarefa binária com saída probabilística\n",
    "        eval_metric=\"aucpr\",          # Foco em PR-AUC (melhor para dados desbalanceados)\n",
    "        tree_method=\"hist\",           # Algoritmo mais rápido para grandes conjuntos\n",
    "        n_jobs=-1,                    # Usa todos os núcleos disponíveis\n",
    "        scale_pos_weight=spw,        # Aplica ponderação automática para balancear classes\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Espaço de busca para tuning dos hiperparâmetros\n",
    "param_dist = {\n",
    "    \"model__n_estimators\":     [300, 600],\n",
    "    \"model__learning_rate\":    [0.03, 0.1],\n",
    "    \"model__max_depth\":        [4, 8],\n",
    "    \"model__min_child_weight\": [1, 3],\n",
    "    \"model__subsample\":        [0.6, 1.0],\n",
    "    \"model__colsample_bytree\": [0.6, 1.0],\n",
    "    \"model__reg_lambda\":       [1.0, 10.0],\n",
    "    \"model__reg_alpha\":        [0.0, 1.0],\n",
    "    \"model__gamma\":            [0.0, 1.0],\n",
    "}\n",
    "\n",
    "# Tuning com validação cruzada (3-fold)\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "rnd = RandomizedSearchCV(\n",
    "    pipe_xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=4,                        # Limita para 4 combinações (mais rápido)\n",
    "    scoring=\"f1\",                   # Otimiza F1-score da classe positiva\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "rnd.fit(X_treino, y_treino)\n",
    "\n",
    "best_xgb = rnd.best_estimator_      # Melhor pipeline treinado\n",
    "melhores_param = rnd.best_params_   # Hiperparâmetros escolhidos\n",
    "melhor_score = rnd.best_score_      # Melhor F1 médio obtido na CV\n",
    "\n",
    "# Função auxiliar para encontrar o melhor threshold com base em F1 via CV\n",
    "def escolher_threshold_cv(estimator, X_train, y_train, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    ths = []\n",
    "    for tr, va in skf.split(X_train, y_train):\n",
    "        estimator.fit(X_train.iloc[tr], y_train.iloc[tr])\n",
    "        p = estimator.predict_proba(X_train.iloc[va])[:, 1]\n",
    "        prec, rec, thr = precision_recall_curve(y_train.iloc[va], p)\n",
    "        f1 = 2*prec*rec/(prec+rec+1e-12)\n",
    "        i = int(np.nanargmax(f1))  # Índice do melhor F1\n",
    "        th = thr[i-1] if i > 0 and i-1 < len(thr) else 0.5\n",
    "        ths.append(float(th))\n",
    "    return float(np.median(ths))  # Threshold final = mediana entre folds\n",
    "\n",
    "thr_star = escolher_threshold_cv(best_xgb, X_treino, y_treino, n_splits=5)\n",
    "\n",
    "# Avaliação final no conjunto de teste\n",
    "prob = best_xgb.predict_proba(X_teste)[:, 1]   # Probabilidade da classe positiva\n",
    "predCV = (prob >= thr_star).astype(int)        # Aplicação do threshold otimizado\n",
    "\n",
    "# Impressão dos resultados\n",
    "print(f\"\\nMelhores parâmetros (XGBoost + Tuning): {melhores_param}\")\n",
    "print(f\"Melhor F1-score (CV): {melhor_score}\")\n",
    "\n",
    "print(\"\\n== XGBoost Tunado ==\")\n",
    "print(classification_report(y_teste, predCV))                      # Métricas finais no teste\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_teste, prob))                   # Área sob a curva ROC\n",
    "print(\"PR-AUC :\", average_precision_score(y_teste, prob))         # Área sob a curva PR\n"
   ],
   "id": "9bee7d8b83f16a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "\n",
      "Melhores parâmetros (XGBoost + Tuning): {'model__subsample': 0.6, 'model__reg_lambda': 1.0, 'model__reg_alpha': 1.0, 'model__n_estimators': 600, 'model__min_child_weight': 3, 'model__max_depth': 4, 'model__learning_rate': 0.1, 'model__gamma': 0.0, 'model__colsample_bytree': 1.0}\n",
      "Melhor F1-score (CV): 0.39674845055961\n",
      "\n",
      "== XGBoost Tunado ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.64      0.74      4595\n",
      "           1       0.28      0.59      0.38      1104\n",
      "\n",
      "    accuracy                           0.63      5699\n",
      "   macro avg       0.58      0.62      0.56      5699\n",
      "weighted avg       0.75      0.63      0.67      5699\n",
      "\n",
      "ROC-AUC: 0.6718528725300027\n",
      "PR-AUC : 0.32716825702824337\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparação Quantitativa",
   "id": "548c6f141757d05b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T00:57:47.066652Z",
     "start_time": "2025-11-27T00:57:47.061317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Resultados antes e depois de cada modelo\n",
    "dados = {\n",
    "    \"Modelo\": [\n",
    "        \"LogReg (baseline)\",\n",
    "        \"LogReg + UnderSampling + Tuning\",\n",
    "        \"Random Forest (baseline)\",\n",
    "        \"Random Forest + Tuning\",\n",
    "        \"XGBoost (baseline)\",\n",
    "        \"XGBoost + Tuning + Threshold CV\"\n",
    "    ],\n",
    "    \"Precision (classe 1)\": [0.45, 0.28, 0.15, 0.28, 0.48, 0.28],\n",
    "    \"Recall (classe 1)\":    [0.09, 0.62, 0.04, 0.63, 0.06, 0.59],\n",
    "    \"F1-score (classe 1)\":  [0.15, 0.39, 0.07, 0.38, 0.10, 0.38],\n",
    "    \"ROC-AUC\":              [0.68, 0.67, 0.64, 0.66, 0.68, 0.67],\n",
    "    \"PR-AUC\":               [None, None, None, 0.30, None, 0.33]\n",
    "}\n",
    "\n",
    "df_comp = pd.DataFrame(dados)\n",
    "df_comp.set_index(\"Modelo\", inplace=True)\n",
    "df_comp\n"
   ],
   "id": "49450bac58889496",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                 Precision (classe 1)  Recall (classe 1)  \\\n",
       "Modelo                                                                     \n",
       "LogReg (baseline)                                0.45               0.09   \n",
       "LogReg + UnderSampling + Tuning                  0.28               0.62   \n",
       "Random Forest (baseline)                         0.15               0.04   \n",
       "Random Forest + Tuning                           0.28               0.63   \n",
       "XGBoost (baseline)                               0.48               0.06   \n",
       "XGBoost + Tuning + Threshold CV                  0.28               0.59   \n",
       "\n",
       "                                 F1-score (classe 1)  ROC-AUC  PR-AUC  \n",
       "Modelo                                                                 \n",
       "LogReg (baseline)                               0.15     0.68     NaN  \n",
       "LogReg + UnderSampling + Tuning                 0.39     0.67     NaN  \n",
       "Random Forest (baseline)                        0.07     0.64     NaN  \n",
       "Random Forest + Tuning                          0.38     0.66    0.30  \n",
       "XGBoost (baseline)                              0.10     0.68     NaN  \n",
       "XGBoost + Tuning + Threshold CV                 0.38     0.67    0.33  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision (classe 1)</th>\n",
       "      <th>Recall (classe 1)</th>\n",
       "      <th>F1-score (classe 1)</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>PR-AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modelo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg (baseline)</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.68</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg + UnderSampling + Tuning</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.67</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest (baseline)</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest + Tuning</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost (baseline)</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost + Tuning + Threshold CV</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Variáveis Mais Influentes",
   "id": "19dd00767fd01609"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T01:11:34.325941Z",
     "start_time": "2025-11-27T01:11:34.282051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Função auxiliar para obter os nomes das features após o preprocessador\n",
    "def get_feature_names(prep):\n",
    "    return prep.get_feature_names_out()\n",
    "\n",
    "# ==============================\n",
    "# 1. Regressão Logística\n",
    "# ==============================\n",
    "modelo_lr = best_lr.named_steps[\"model\"]\n",
    "prep_lr = best_lr.named_steps[\"prep\"]\n",
    "features_lr = get_feature_names(prep_lr)\n",
    "\n",
    "coef = modelo_lr.coef_.flatten()\n",
    "assert len(features_lr) == len(coef), \"Número de coeficientes não bate com número de features\"\n",
    "\n",
    "df_coef = pd.DataFrame({\n",
    "    \"feature\": features_lr,\n",
    "    \"coef\": coef,\n",
    "    \"abs_coef\": np.abs(coef)\n",
    "}).sort_values(by=\"abs_coef\", ascending=False)\n",
    "\n",
    "print(\"Top 15 variáveis mais impactantes - Regressão Logística:\")\n",
    "print(df_coef.head(15))\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 2. Random Forest\n",
    "# ==============================\n",
    "best_rf = grid_fast.best_estimator_\n",
    "modelo_rf = best_rf.named_steps[\"model\"]\n",
    "prep_rf = best_rf.named_steps[\"prep\"]\n",
    "features_rf = get_feature_names(prep_rf)\n",
    "\n",
    "importancias_rf = modelo_rf.feature_importances_\n",
    "assert len(features_rf) == len(importancias_rf), \"Número de importâncias ≠ número de features\"\n",
    "\n",
    "df_rf = pd.DataFrame({\n",
    "    \"feature\": features_rf,\n",
    "    \"importance\": importancias_rf\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 variáveis mais importantes - Random Forest:\")\n",
    "print(df_rf.head(15))\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 3. XGBoost\n",
    "# ==============================\n",
    "modelo_xgb = best_xgb.named_steps[\"model\"]\n",
    "prep_xgb = best_xgb.named_steps[\"prep\"]\n",
    "features_xgb = get_feature_names(prep_xgb)\n",
    "\n",
    "importancias_xgb = modelo_xgb.feature_importances_\n",
    "assert len(features_xgb) == len(importancias_xgb), \"Número de importâncias ≠ número de features\"\n",
    "\n",
    "df_xgb = pd.DataFrame({\n",
    "    \"feature\": features_xgb,\n",
    "    \"importance\": importancias_xgb\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 variáveis mais importantes - XGBoost:\")\n",
    "print(df_xgb.head(15))\n"
   ],
   "id": "56d3eafb5bb2b369",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 variáveis mais impactantes - Regressão Logística:\n",
      "                                                 feature      coef  abs_coef\n",
      "1476                         cat__PERP_AGE_GROUP_UNKNOWN -2.590643  2.590643\n",
      "1480                               cat__PERP_SEX_UNKNOWN  2.276037  2.276037\n",
      "956                             cat__OCCUR_TIME_16:25:00 -1.594320  1.594320\n",
      "6329   cat__Lon_Lat_POINT (-73.90317908399999 40.8248...  1.583077  1.583077\n",
      "10450  cat__Lon_Lat_POINT (-73.94364075199996 40.6892...  1.492544  1.492544\n",
      "24                              cat__OCCUR_TIME_00:19:00 -1.398520  1.398520\n",
      "1243                            cat__OCCUR_TIME_21:12:00  1.382360  1.382360\n",
      "986                             cat__OCCUR_TIME_16:55:00 -1.373565  1.373565\n",
      "1115                            cat__OCCUR_TIME_19:04:00 -1.347919  1.347919\n",
      "11154  cat__Lon_Lat_POINT (-73.95082167399994 40.6488...  1.337668  1.337668\n",
      "10020  cat__Lon_Lat_POINT (-73.93999542099994 40.7887...  1.285601  1.285601\n",
      "8829           cat__Lon_Lat_POINT (-73.926713 40.671245)  1.280905  1.280905\n",
      "4850   cat__Lon_Lat_POINT (-73.88417317899996 40.8528...  1.278413  1.278413\n",
      "259                             cat__OCCUR_TIME_04:14:00  1.268983  1.268983\n",
      "736                             cat__OCCUR_TIME_12:45:00  1.248609  1.248609\n",
      "\n",
      "Top 15 variáveis mais importantes - Random Forest:\n",
      "                                         feature  importance\n",
      "0                              num__INCIDENT_KEY    0.141066\n",
      "1476                 cat__PERP_AGE_GROUP_UNKNOWN    0.133202\n",
      "4                                num__Y_COORD_CD    0.075050\n",
      "3                                num__X_COORD_CD    0.070503\n",
      "1480                       cat__PERP_SEX_UNKNOWN    0.058971\n",
      "1472                   cat__PERP_AGE_GROUP_25-44    0.049760\n",
      "1                                  num__PRECINCT    0.047087\n",
      "1479                          cat__PERP_SEX_MALE    0.033947\n",
      "1486                      cat__PERP_RACE_UNKNOWN    0.031852\n",
      "1466                  cat__LOCATION_DESC_UNKNOWN    0.029719\n",
      "1493                      cat__VIC_AGE_GROUP_<18    0.027442\n",
      "1453  cat__LOCATION_DESC_MULTI DWELL - APT BUILD    0.023834\n",
      "1457                cat__LOCATION_DESC_PVT HOUSE    0.021529\n",
      "1490                    cat__VIC_AGE_GROUP_25-44    0.021406\n",
      "1473                   cat__PERP_AGE_GROUP_45-64    0.019115\n",
      "\n",
      "Top 15 variáveis mais importantes - XGBoost:\n",
      "                                                feature  importance\n",
      "1461                              cat__PERP_SEX_UNKNOWN    0.018897\n",
      "1457                        cat__PERP_AGE_GROUP_UNKNOWN    0.010546\n",
      "1454                          cat__PERP_AGE_GROUP_45-64    0.005210\n",
      "1473                             cat__VIC_AGE_GROUP_<18    0.004943\n",
      "1399                     cat__LOC_OF_OCCUR_DESC_OUTSIDE    0.004798\n",
      "1467                               cat__PERP_RACE_WHITE    0.003919\n",
      "1447                         cat__LOCATION_DESC_UNKNOWN    0.003885\n",
      "2                                num__JURISDICTION_CODE    0.003774\n",
      "1453                          cat__PERP_AGE_GROUP_25-44    0.003749\n",
      "1435       cat__LOCATION_DESC_MULTI DWELL - PUBLIC HOUS    0.003711\n",
      "1407                     cat__LOC_CLASSFCTN_DESC_STREET    0.003574\n",
      "8669  cat__Lon_Lat_POINT (-73.93842477199996 40.6803...    0.003478\n",
      "1450                         cat__PERP_AGE_GROUP_(NULL)    0.003342\n",
      "1466                             cat__PERP_RACE_UNKNOWN    0.003335\n",
      "1153                           cat__OCCUR_TIME_20:00:00    0.003310\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Conclusão",
   "id": "e78411a63d9c1873"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Durante o desenvolvimento do projeto, observou-se que abordagens padrão e desbalanceadas, como Regressão Logística, Random Forest e XGBoost sem ajuste de classes, apresentaram desempenho insatisfatório, especialmente na detecção da classe minoritária, responsável por representar os tiroteios letais. Esses modelos obtiveram baixos valores de F1-score e recall para a classe 1, evidenciando a necessidade de estratégias específicas para lidar com o desbalanceamento de classes. Nesse sentido, técnicas como o uso de class_weight=\"balanced\" e, sobretudo, o undersampling via RandomUnderSampler se mostraram eficazes, promovendo melhorias expressivas em recall e F1-score da classe de interesse, mesmo com alguma perda de acurácia geral. Tais resultados indicam que, embora o desempenho para a classe majoritária seja impactado, os modelos tornam-se mais justos e sensíveis à detecção de eventos relevantes para a análise.\n",
    "\n",
    "Com o avanço das iterações, a aplicação de Random Forest com tuning foi explorada como alternativa eficiente do ponto de vista computacional, alcançando F1-score competitivo e boa capacidade de generalização. No entanto, persistiu o problema de baixa precisão para a classe minoritária, indicando a presença de elevado número de falsos positivos. Em seguida, a utilização do XGBoost com tuning e definição de threshold personalizado por validação cruzada revelou-se a abordagem mais equilibrada, atingindo o melhor F1-score no processo de validação e resultados consistentes no conjunto de teste. A escolha de um limiar de decisão otimizado, em vez de utilizar o valor padrão de 0.5, foi crucial para adaptar o modelo à distribuição real do problema e maximizar a efetividade da classificação.\n",
    "\n",
    "Ao longo do processo, foram empregadas métricas de performance apropriadas ao problema de classificação binária desbalanceada, como F1-score, recall, ROC-AUC e PR-AUC, de forma a capturar a habilidade dos modelos em identificar corretamente os tiroteios letais. A regressão logística, usada como baseline, apresentou desempenho limitado (F1 = 0.15; recall = 0.09), sendo posteriormente aprimorada com técnicas de undersampling e tuning, o que elevou seu F1-score para 0.39. Modelos baseados em árvores, como Random Forest e XGBoost, atingiram F1-scores similares (até 0.38), com XGBoost se destacando em PR-AUC (0.33), evidenciando maior robustez para o contexto do problema.\n",
    "\n",
    "No que tange à explicabilidade, a regressão logística permitiu análise direta dos coeficientes, revelando que variáveis como horário do crime e categorias desconhecidas (“UNKNOWN”/\"Null\") relativas ao sexo e idade do agressor estavam entre as mais influentes. Em contrapartida, Random Forest e XGBoost apontaram como mais importantes os atributos relacionados à localização geográfica, ao perfil do autor e ao tipo de ocorrência, contribuindo para a validação das hipóteses de que o contexto espacial e temporal, bem como o perfil das partes envolvidas, influenciam significativamente a letalidade dos tiroteios. Ainda assim, notou-se um claro trade-off entre interpretabilidade e complexidade: modelos lineares oferecem maior transparência, enquanto modelos de árvore, embora mais eficazes, exigem técnicas adicionais para interpretação. Por fim, limitações como o desbalanceamento residual, a presença de dados incompletos e a potencial limitação na generalização dos modelos para novos contextos foram reconhecidas, reforçando a necessidade de um equilíbrio criterioso entre desempenho preditivo e capacidade explicativa na escolha do modelo final."
   ],
   "id": "63ae8e813a6adbe4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
